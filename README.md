# Langchain-Q-A
 "Article QA" app uses OpenAI's LLM to answer questions on news articles. Users input URLs, and the app extracts text using FAISS for vectorization. Queries trigger the LLM to generate answers.


## Article QA Streamlit App

This Streamlit app enables users to analyze news articles and ask questions about them using OpenAI's Language Model (LLM). The app extracts text from provided article URLs, processes it for question-answering, and displays the generated answers.

### Features:

- **Input URLs**: Users can input URLs of news articles through the Streamlit interface.
- **Data Extraction**: Upon clicking the "Read" button, the app extracts text from the provided URLs.
- **Question-Answering**: Users can ask questions about the extracted content using a text input field.
- **Answer Generation**: The app utilizes FAISS for document vectorization and RetrievalQAWithSourcesChain for question-answering with the LLM.
- **Streamlit Interface**: The answers generated by the LLM are displayed in the Streamlit interface.

### Usage:

1. **Install Dependencies**: Ensure that the required libraries and modules are installed. Use `pip install -r requirements.txt` to install them.
2. **Set Up OpenAI API Key**: Set the API key for the OpenAI service in the environment variable `OPENAI_API_KEY`.
3. **Run the App**: Execute the script `main.py` and access the app through the provided URL.
4. **Input URLs**: Input the URLs of news articles in the sidebar of the app.
5. **Generate Answers**: Click the "Read" button to extract text from the provided URLs. Enter questions in the text input field to generate answers.

### Technologies Used:

- **OpenAI**: Utilized for the Language Model for question-answering.
- **Streamlit**: Used to create the user interface for the app.
- **FAISS**: Employed for efficient document vectorization
